"""
ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ì´ë¯¸ì§€ ì§ˆë¬¸-ì‘ë‹µ API
Qwen2-VL-2B (ì˜ì–´) + M2M100 ë²ˆì—­ (í•œêµ­ì–´)
ê°œì„ : ì§ˆë¬¸ ë§¤í•‘ ìš°ì„ ìˆœìœ„, ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬, ë²ˆì—­ í›„ì²˜ë¦¬
"""

import io
import base64
import re
import asyncio
import gc
from contextlib import asynccontextmanager
from typing import Optional, AsyncGenerator
from threading import Thread

import torch
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from PIL import Image

# ì „ì—­ ë³€ìˆ˜
vl_model = None
vl_processor = None
translator = None
translator_tokenizer = None
device = None

# ëª¨ë¸ ì„¤ì •
VL_MODEL_ID = "Qwen/Qwen2-VL-2B-Instruct"
TRANSLATOR_MODEL_ID = "facebook/m2m100_418M"


# =============================================
# ì§ˆë¬¸ ë§¤í•‘ (ìš°ì„ ìˆœìœ„: ê¸´ íŒ¨í„´ë¶€í„°)
# =============================================

# ì£¼ì–´ (ëŒ€ìƒ) ë§¤í•‘ - í’ê²½ ìš”ì†Œ
SUBJECT_MAP = {
    # ìì—°
    "ì‚°": "the mountain",
    "ì‚°ì´": "the mountain",
    "ë°”ë‹¤": "the ocean",
    "ë°”ë‹¤ê°€": "the ocean",
    "í˜¸ìˆ˜": "the lake",
    "í˜¸ìˆ˜ê°€": "the lake",
    "ê°•": "the river",
    "ê°•ì´": "the river",
    "í•˜ëŠ˜": "the sky",
    "í•˜ëŠ˜ì´": "the sky",
    "êµ¬ë¦„": "the clouds",
    "êµ¬ë¦„ì´": "the clouds",
    "ë‚˜ë¬´": "the trees",
    "ë‚˜ë¬´ê°€": "the trees",
    "ìˆ²": "the forest",
    "ìˆ²ì´": "the forest",
    "ê½ƒ": "the flowers",
    "ê½ƒì´": "the flowers",
    "í•´": "the sun",
    "í•´ê°€": "the sun",
    "ë‹¬": "the moon",
    "ë‹¬ì´": "the moon",
    "ë³„": "the stars",
    "ë³„ì´": "the stars",
    "ëˆˆ": "the snow",
    "ë¹„": "the rain",
    "ì•ˆê°œ": "the fog",
    "ë…¸ì„": "the sunset",
    "ì¼ì¶œ": "the sunrise",
    
    # ì§€í˜•
    "ì–¸ë•": "the hill",
    "ì ˆë²½": "the cliff",
    "í•´ë³€": "the beach",
    "ëª¨ë˜": "the sand",
    "ë°”ìœ„": "the rocks",
    "í­í¬": "the waterfall",
    "ë“¤íŒ": "the field",
    "ì´ˆì›": "the meadow",
    
    # ì¸ê³µë¬¼
    "ê±´ë¬¼": "the building",
    "ì§‘": "the house",
    "ë‹¤ë¦¬": "the bridge",
    "ê¸¸": "the road",
    "ë°°": "the boat",
    "ë“±ëŒ€": "the lighthouse",
}

# ì§ˆë¬¸ ìœ í˜• ë§¤í•‘ (í’ê²½ ìµœì í™”)
QUESTION_MAP = [
    # ì „ì²´ í’ê²½
    ("ë­ê°€ ìˆì–´", "Describe this landscape scene."),
    ("ë­ê°€ ë³´ì—¬", "Describe this landscape scene."),
    ("ì•ì— ë­", "What is in the foreground?"),
    ("ë­ ìˆì–´", "Describe this scene."),
    ("ì„¤ëª…í•´", "Describe this landscape in detail."),
    
    # ìœ„ì¹˜ë³„
    ("ì•ìª½", "What is in the foreground?"),
    ("ë’¤ìª½", "What is in the background?"),
    ("ê°€ìš´ë°", "What is in the center?"),
    ("ë©€ë¦¬", "What is in the distance?"),
    ("ê°€ê¹Œì´", "What is nearby?"),
    
    # ìì—° ìš”ì†Œ
    ("í•˜ëŠ˜", "Describe the sky."),
    ("êµ¬ë¦„", "Describe the clouds."),
    ("ì‚°", "Describe the mountains."),
    ("ë°”ë‹¤", "Describe the ocean or sea."),
    ("í˜¸ìˆ˜", "Describe the lake."),
    ("ê°•", "Describe the river."),
    ("ë‚˜ë¬´", "Describe the trees."),
    ("ìˆ²", "Describe the forest."),
    ("ê½ƒ", "Describe the flowers."),
    ("í•´", "Describe the sun."),
    ("ë‹¬", "Describe the moon."),
    
    # ë¶„ìœ„ê¸°/ì‹œê°„
    ("ë¶„ìœ„ê¸°", "What is the mood or atmosphere?"),
    ("ëŠë‚Œ", "What is the mood or atmosphere?"),
    ("ë‚ ì”¨", "What is the weather like?"),
    ("ì‹œê°„", "What time of day is it?"),
    ("ê³„ì ˆ", "What season does it look like?"),
    ("ì•„ì¹¨", "Is this morning or sunrise?"),
    ("ì €ë…", "Is this evening or sunset?"),
    ("ë‚®", "Is this daytime?"),
    ("ë°¤", "Is this nighttime?"),
    
    # ìƒ‰ìƒ
    ("ë¬´ìŠ¨ ìƒ‰", "What colors do you see?"),
    ("ë¬´ìŠ¨ìƒ‰", "What colors do you see?"),
    ("ìƒ‰ê¹”", "What are the main colors?"),
    ("ìƒ‰ì´", "What colors are there?"),
    
    # ë‚ ì”¨
    ("ë§‘", "Is it clear or sunny?"),
    ("í", "Is it cloudy?"),
    ("ë¹„", "Is it raining?"),
    ("ëˆˆ", "Is it snowing?"),
    ("ì•ˆê°œ", "Is there fog or mist?"),
    
    # ê±´ë¬¼/ì¸ê³µë¬¼
    ("ê±´ë¬¼", "Are there any buildings?"),
    ("ì§‘", "Are there any houses?"),
    ("ë‹¤ë¦¬", "Is there a bridge?"),
    ("ê¸¸", "Is there a road or path?"),
    
    # ì¼ë°˜
    ("ì–´ë””", "What place is this?"),
    ("ì¥ì†Œ", "What kind of place is this?"),
    ("ì–´ë•Œ", "How does this scene look?"),
    ("ì˜ˆë»", "Is this beautiful?"),
]


def convert_question_to_english(question: str) -> str:
    """í•œêµ­ì–´ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë³€í™˜ (ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬)"""
    
    # 1. ì£¼ì–´(ëŒ€ìƒ) ì°¾ê¸°
    subject = "it"
    found_subject_ko = None
    for ko, en in SUBJECT_MAP.items():
        if ko in question:
            subject = en
            found_subject_ko = ko
            break
    
    # 2. ì§ˆë¬¸ ìœ í˜• ì°¾ê¸° (ê¸´ íŒ¨í„´ë¶€í„° ì²´í¬)
    for pattern, en_template in QUESTION_MAP:
        if pattern in question:
            en_question = en_template.replace("{subject}", subject)
            return en_question
    
    # 3. ì£¼ì–´ë§Œ ìˆê³  ì§ˆë¬¸ ìœ í˜•ì´ ì—†ìœ¼ë©´ â†’ ì„¤ëª… ìš”ì²­
    if found_subject_ko:
        return f"Describe {subject}."
    
    # 4. ê¸°ë³¸ê°’ - í’ê²½ ì„¤ëª…
    return "Describe this landscape scene."


# =============================================
# ë²ˆì—­ í›„ì²˜ë¦¬
# =============================================

def clean_translation(text: str) -> str:
    """ë²ˆì—­ ê²°ê³¼ ì •ë¦¬ (í’ê²½ ì„¤ëª… ìµœì í™”)"""
    if not text:
        return ""
    
    # ì¤‘ë³µ ë‹¨ì–´ ì œê±°
    text = re.sub(r'\b(\w+)\s+\1\b', r'\1', text)
    
    # ì´ìƒí•œ ë¬¸ì ì œê±°
    text = re.sub(r'[!]{2,}', '!', text)
    text = re.sub(r'[.]{2,}', '.', text)
    text = re.sub(r'\s+', ' ', text)
    
    # ë¶ˆí•„ìš”í•œ ë²ˆì—­íˆ¬ í‘œí˜„ ì œê±°
    remove_patterns = [
        r'ì´ë¯¸ì§€ì—ì„œ\s*',
        r'ì‚¬ì§„ì—ì„œ\s*',
        r'ê·¸ê²ƒì€\s*',
        r'ì´ê²ƒì€\s*',
        r'^ì˜ˆ[,.\s]*',
        r'^ë„¤[,.\s]*',
    ]
    for pattern in remove_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë³€í™˜
    replacements = [
        # ì¡´ëŒ“ë§ ë³€í™˜
        ('ì…ë‹ˆë‹¤.', 'ì´ì—ìš”.'),
        ('ìˆìŠµë‹ˆë‹¤.', 'ìˆì–´ìš”.'),
        ('ì—†ìŠµë‹ˆë‹¤.', 'ì—†ì–´ìš”.'),
        ('ë©ë‹ˆë‹¤.', 'ë¼ìš”.'),
        ('í•©ë‹ˆë‹¤.', 'í•´ìš”.'),
        ('ë´…ë‹ˆë‹¤.', 'ë´ìš”.'),
        ('ìŠµë‹ˆë‹¤.', 'ì–´ìš”.'),
        ('ã…‚ë‹ˆë‹¤.', 'ìš”.'),
        ('ì´ë‹¤.', 'ì´ì—ìš”.'),
        ('ìˆë‹¤.', 'ìˆì–´ìš”.'),
        ('ì—†ë‹¤.', 'ì—†ì–´ìš”.'),
        ('í•œë‹¤.', 'í•´ìš”.'),
        ('ë³´ì¸ë‹¤.', 'ë³´ì—¬ìš”.'),
        ('ëœë‹¤.', 'ë¼ìš”.'),
        
        # í’ê²½ ê´€ë ¨ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
        ('ë°˜ì‚¬', 'ë¹„ì¹˜ê³ '),
        ('ë°˜ì˜', 'ë¹„ì¹˜ê³ '),
        ('ìœ„ì¹˜í•˜ê³ ', 'ìˆê³ '),
        ('ì¡´ì¬í•˜ê³ ', 'ìˆê³ '),
    ]
    for old, new in replacements:
        text = text.replace(old, new)
    
    # ë¬¸ì¥ ì •ë¦¬
    text = text.strip()
    text = re.sub(r'^[.,\s]+', '', text)
    text = re.sub(r'\s+', ' ', text)
    
    # ë¬¸ì¥ ë ìì—°ìŠ¤ëŸ½ê²Œ
    if text and not text[-1] in '.!?ìš”':
        if text[-1] in 'ë‹¤':
            text = text[:-1] + 'ìš”.'
        else:
            text += 'ìš”.'
    
    return text.strip()


# =============================================
# ëª¨ë¸ ë¡œë“œ
# =============================================

def load_models():
    """VL ëª¨ë¸ + ë²ˆì—­ ëª¨ë¸ ë¡œë“œ"""
    global vl_model, vl_processor, translator, translator_tokenizer, device
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ Using device: {device}")
    
    if device == "cuda":
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
        gc.collect()
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    try:
        # 1. Vision-Language ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ“¦ Loading VL model: {VL_MODEL_ID}")
        from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
        
        vl_processor = AutoProcessor.from_pretrained(
            VL_MODEL_ID, 
            trust_remote_code=True,
            min_pixels=256*28*28,
            max_pixels=512*28*28,
        )
        vl_model = Qwen2VLForConditionalGeneration.from_pretrained(
            VL_MODEL_ID,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            device_map="auto" if device == "cuda" else None,
            trust_remote_code=True,
        )
        print("âœ… VL model loaded!")
        
        # 2. ë²ˆì—­ ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ“¦ Loading translator: {TRANSLATOR_MODEL_ID}")
        from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer
        
        translator_tokenizer = M2M100Tokenizer.from_pretrained(TRANSLATOR_MODEL_ID)
        translator = M2M100ForConditionalGeneration.from_pretrained(TRANSLATOR_MODEL_ID)
        
        if device == "cuda":
            translator = translator.to(device)
        
        print("âœ… Translator loaded!")
        print("ğŸš€ All models ready!")
        
    except Exception as e:
        print(f"âŒ Model loading failed: {e}")
        raise e


def translate_to_korean(text: str) -> str:
    """ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (M2M100)"""
    global translator, translator_tokenizer, device
    
    if not text.strip():
        return ""
    
    try:
        # ì†ŒìŠ¤ ì–¸ì–´ ì„¤ì • (ì˜ì–´)
        translator_tokenizer.src_lang = "en"
        
        # í•œ ë²ˆì— ë²ˆì—­ (ë¬¸ì¥ ë¶„ë¦¬ X â†’ ë” ìì—°ìŠ¤ëŸ¬ì›€)
        inputs = translator_tokenizer(
            text, 
            return_tensors="pt", 
            padding=True, 
            truncation=True, 
            max_length=256
        )
        
        if device == "cuda":
            inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            generated_tokens = translator.generate(
                **inputs,
                forced_bos_token_id=translator_tokenizer.get_lang_id("ko"),
                max_length=256,
                num_beams=3,  # ë¹” ì„œì¹˜ë¡œ í’ˆì§ˆ í–¥ìƒ
            )
        
        translated = translator_tokenizer.batch_decode(
            generated_tokens, 
            skip_special_tokens=True
        )[0]
        
        # í›„ì²˜ë¦¬
        return clean_translation(translated)
        
    except Exception as e:
        print(f"Translation error: {e}")
        return text  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜


# =============================================
# FastAPI ì•±
# =============================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    load_models()
    yield
    # ì •ë¦¬
    global vl_model, vl_processor, translator, translator_tokenizer
    del vl_model, vl_processor, translator, translator_tokenizer
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()


app = FastAPI(
    title="Vision Assistant API",
    description="ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ì´ë¯¸ì§€ ì§ˆë¬¸-ì‘ë‹µ API",
    version="2.0.0",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class QuestionRequest(BaseModel):
    image_base64: str
    question: str
    language: str = "ko"


class AnswerResponse(BaseModel):
    answer: str
    success: bool
    error: Optional[str] = None


def process_image(image_data: str) -> Image.Image:
    """Base64 ì´ë¯¸ì§€ ë””ì½”ë”©"""
    try:
        if "," in image_data:
            image_data = image_data.split(",")[1]
        image_bytes = base64.b64decode(image_data)
        return Image.open(io.BytesIO(image_bytes)).convert("RGB")
    except Exception as e:
        raise ValueError(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")


# ì˜ì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í’ê²½ ì„¤ëª… ìµœì í™”)
SYSTEM_PROMPT = """You are describing a scenic landscape for a visually impaired person.

Describe in this order:
1. Overall scene (mountain, ocean, forest, city, etc.)
2. Sky and lighting (sunrise, sunset, cloudy, clear)
3. Main elements from front to back
4. Colors and atmosphere
5. Any notable details

Be vivid but natural. Around 2-3 sentences."""


def generate_english_answer(image: Image.Image, question: str) -> str:
    """ì˜ì–´ë¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
    global vl_model, vl_processor, device
    
    from qwen_vl_utils import process_vision_info
    
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": question},
            ],
        }
    ]
    
    text = vl_processor.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    
    image_inputs, video_inputs = process_vision_info(messages)
    
    inputs = vl_processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    )
    
    if device == "cuda":
        inputs = inputs.to("cuda")
    
    with torch.no_grad():
        generated_ids = vl_model.generate(
            **inputs,
            max_new_tokens=80,  # í’ê²½ ì„¤ëª…ì€ ì¢€ ë” ê¸¸ê²Œ
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.3,
        )
    
    generated_ids_trimmed = [
        out_ids[len(in_ids):] 
        for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    answer = vl_processor.batch_decode(
        generated_ids_trimmed, 
        skip_special_tokens=True, 
        clean_up_tokenization_spaces=False
    )[0]
    
    return answer.strip()


def generate_answer(image: Image.Image, question: str, language: str = "ko") -> str:
    """ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
    
    # í•œêµ­ì–´ ì§ˆë¬¸ â†’ ì˜ì–´ ë³€í™˜
    if language == "ko":
        en_question = convert_question_to_english(question)
        print(f"ğŸ”„ ì§ˆë¬¸ ë³€í™˜: '{question}' â†’ '{en_question}'")
    else:
        en_question = question
    
    # ì˜ì–´ë¡œ ë‹µë³€ ìƒì„±
    english_answer = generate_english_answer(image, en_question)
    print(f"ğŸ‡ºğŸ‡¸ ì˜ì–´ ë‹µë³€: {english_answer}")
    
    # í•œêµ­ì–´ë¡œ ë²ˆì—­
    if language == "ko":
        korean_answer = translate_to_korean(english_answer)
        print(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë‹µë³€: {korean_answer}")
        return korean_answer
    
    return english_answer


async def generate_stream(image: Image.Image, question: str, language: str = "ko") -> AsyncGenerator[str, None]:
    """ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„±"""
    
    # í•œêµ­ì–´ ì§ˆë¬¸ â†’ ì˜ì–´ ë³€í™˜
    if language == "ko":
        en_question = convert_question_to_english(question)
    else:
        en_question = question
    
    # ì˜ì–´ ë‹µë³€ ìƒì„±
    english_answer = generate_english_answer(image, en_question)
    
    # í•œêµ­ì–´ ë²ˆì—­
    if language == "ko":
        final_answer = translate_to_korean(english_answer)
    else:
        final_answer = english_answer
    
    # í•œ ê¸€ìì”© ìŠ¤íŠ¸ë¦¬ë°
    for char in final_answer:
        yield char
        await asyncio.sleep(0.02)


# =============================================
# API ì—”ë“œí¬ì¸íŠ¸
# =============================================

@app.get("/")
async def root():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "running",
        "version": "2.0.0",
        "vl_model": VL_MODEL_ID,
        "translator": TRANSLATOR_MODEL_ID,
        "cuda_available": torch.cuda.is_available(),
        "features": ["ì§ˆë¬¸ ë§¤í•‘ ê°œì„ ", "ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬", "ë²ˆì—­ í›„ì²˜ë¦¬", "ì¹œê·¼í•œ ë§íˆ¬"]
    }


@app.post("/api/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """ì´ë¯¸ì§€ ì§ˆë¬¸ ë‹µë³€"""
    try:
        image = process_image(request.image_base64)
        answer = generate_answer(image, request.question, request.language)
        return AnswerResponse(answer=answer, success=True)
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return AnswerResponse(answer="ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", success=False, error=str(e))


@app.post("/api/ask-stream")
async def ask_question_stream(request: QuestionRequest):
    """ì´ë¯¸ì§€ ì§ˆë¬¸ ë‹µë³€ (ìŠ¤íŠ¸ë¦¬ë°)"""
    try:
        image = process_image(request.image_base64)
        
        async def event_generator():
            async for chunk in generate_stream(image, request.question, request.language):
                yield f"data: {chunk}\n\n"
            yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )
    except Exception as e:
        print(f"âŒ Error: {e}")
        return AnswerResponse(answer="ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.", success=False, error=str(e))


@app.post("/api/describe-stream")
async def describe_image_stream(request: QuestionRequest):
    """ì´ë¯¸ì§€ ì „ì²´ ì„¤ëª… (ìŠ¤íŠ¸ë¦¬ë°)"""
    try:
        image = process_image(request.image_base64)
        question = "Describe this landscape scene in detail."
        
        async def event_generator():
            async for chunk in generate_stream(image, question, request.language):
                yield f"data: {chunk}\n\n"
            yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )
    except Exception as e:
        print(f"âŒ Error: {e}")
        return AnswerResponse(answer="ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.", success=False, error=str(e))


@app.post("/api/describe", response_model=AnswerResponse)
async def describe_image(request: QuestionRequest):
    """ì´ë¯¸ì§€ ì „ì²´ ì„¤ëª…"""
    try:
        image = process_image(request.image_base64)
        question = "Describe this landscape scene in detail."
        answer = generate_answer(image, question, request.language)
        return AnswerResponse(answer=answer, success=True)
    except Exception as e:
        print(f"âŒ Error: {e}")
        return AnswerResponse(answer="ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.", success=False, error=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)