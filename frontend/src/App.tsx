import { useState, useRef, useCallback, useEffect } from 'react';
import './App.css';

// Web Speech API íƒ€ì… ì •ì˜
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}

interface SpeechRecognition extends EventTarget {
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null;
  onend: ((this: SpeechRecognition, ev: Event) => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:8000';

interface ConversationItem {
  type: 'question' | 'answer';
  text: string;
  timestamp: Date;
}

function App() {
  // ë¯¸ë””ì–´ ìƒíƒœ
  const [image, setImage] = useState<string | null>(null);
  const [video, setVideo] = useState<string | null>(null);
  const [mediaType, setMediaType] = useState<'image' | 'video'>('image');
  
  // UI ìƒíƒœ
  const [question, setQuestion] = useState('');
  const [conversation, setConversation] = useState<ConversationItem[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [streamingText, setStreamingText] = useState('');
  
  // ìŒì„± ìƒíƒœ
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [ttsEnabled, setTtsEnabled] = useState(true);
  const [isListening, setIsListening] = useState(false);
  
  // ì¹´ë©”ë¼/ë…¹í™” ìƒíƒœ
  const [cameraActive, setCameraActive] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);

  // Refs
  const fileInputRef = useRef<HTMLInputElement>(null);
  const videoFileInputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const questionInputRef = useRef<HTMLTextAreaElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  const conversationEndRef = useRef<HTMLDivElement>(null);
  const abortControllerRef = useRef<AbortController | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const recordingTimerRef = useRef<number | null>(null);

  // ìŠ¤í¬ë¡¤
  useEffect(() => {
    conversationEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [conversation, streamingText]);

  // TTS
  const speak = useCallback((text: string) => {
    if (!ttsEnabled || !('speechSynthesis' in window)) return;
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 0.9;
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => setIsSpeaking(false);
    utterance.onerror = () => setIsSpeaking(false);
    window.speechSynthesis.speak(utterance);
  }, [ttsEnabled]);

  const stopSpeaking = useCallback(() => {
    window.speechSynthesis.cancel();
    setIsSpeaking(false);
  }, []);

  // STT ì´ˆê¸°í™”
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.lang = 'ko-KR';
      recognition.continuous = false;
      recognition.interimResults = true;
      recognition.onstart = () => setIsListening(true);
      recognition.onresult = (event: SpeechRecognitionEvent) => {
        const transcript = Array.from(event.results).map(result => result[0].transcript).join('');
        setQuestion(transcript);
      };
      recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
        console.error('STT Error:', event.error);
        setIsListening(false);
        if (event.error === 'not-allowed') {
          setError('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
          speak('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        }
      };
      recognition.onend = () => setIsListening(false);
      recognitionRef.current = recognition;
    }
    return () => { if (recognitionRef.current) recognitionRef.current.abort(); };
  }, [speak]);

  const toggleListening = useCallback(() => {
    if (!recognitionRef.current) {
      setError('ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
      return;
    }
    if (isListening) {
      recognitionRef.current.stop();
    } else {
      recognitionRef.current.start();
      speak('ë§ì”€í•˜ì„¸ìš”.');
    }
  }, [isListening, speak]);

  const stopStreaming = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
    }
  }, []);

  // ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'environment' },
        audio: true, // ë¹„ë””ì˜¤ ë…¹í™”ìš©
      });
      streamRef.current = stream;
      setCameraActive(true);
    } catch (err) {
      console.error('Camera error:', err);
      setError('ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      speak('ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  }, [speak]);

  useEffect(() => {
    if (cameraActive && videoRef.current && streamRef.current) {
      videoRef.current.srcObject = streamRef.current;
      videoRef.current.play().catch(console.error);
      speak('ì¹´ë©”ë¼ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
    }
  }, [cameraActive, speak]);

  const stopCamera = useCallback(() => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
      recordingTimerRef.current = null;
    }
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    setCameraActive(false);
    setIsRecording(false);
    setRecordingTime(0);
  }, [isRecording]);

  // ì‚¬ì§„ ì´¬ì˜
  const capturePhoto = useCallback(() => {
    if (!videoRef.current || !canvasRef.current) return;
    const video = videoRef.current;
    const canvas = canvasRef.current;
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    if (ctx) {
      ctx.drawImage(video, 0, 0);
      const imageData = canvas.toDataURL('image/jpeg', 0.8);
      setImage(imageData);
      setVideo(null);
      setMediaType('image');
      setConversation([]);
      stopCamera();
      speak('ì‚¬ì§„ì´ ì´¬ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    }
  }, [stopCamera, speak]);

// 1ï¸âƒ£ ë…¹í™” ì¤‘ì§€ (ë¨¼ì € ì„ ì–¸)
const stopRecording = useCallback((): void => {
  if (!isRecording) return;

  if (recordingTimerRef.current) {
    clearInterval(recordingTimerRef.current);
    recordingTimerRef.current = null;
  }

  mediaRecorderRef.current?.stop();
  setIsRecording(false);
}, [isRecording]);


// 2ï¸âƒ£ ë…¹í™” ì‹œì‘
const startRecording = useCallback((): void => {
  if (!streamRef.current) return;

  recordedChunksRef.current = [];

  const mediaRecorder = new MediaRecorder(streamRef.current, {
    mimeType: 'video/webm',
  });

  mediaRecorder.ondataavailable = (event: BlobEvent) => {
    if (event.data.size > 0) {
      recordedChunksRef.current.push(event.data);
    }
  };

  mediaRecorder.onstop = () => {
    const blob = new Blob(recordedChunksRef.current, { type: 'video/webm' });
    const reader = new FileReader();

    reader.onloadend = () => {
      const base64 = reader.result as string;
      setVideo(base64);
      setImage(null);
      setMediaType('video');
      setConversation([]);
      stopCamera();
      speak('ì˜ìƒì´ ë…¹í™”ë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    };

    reader.readAsDataURL(blob);
  };

  mediaRecorderRef.current = mediaRecorder;
  mediaRecorder.start();

  setIsRecording(true);
  setRecordingTime(0);

  // â±ï¸ 10ì´ˆ ìë™ ì¤‘ì§€
  recordingTimerRef.current = window.setInterval(() => {
    setRecordingTime(prev => {
      if (prev >= 9) {
        stopRecording(); // âœ… ìë™ ì¤‘ì§€ + ë²„íŠ¼ ìƒíƒœ ë³µêµ¬
        return 10;
      }
      return prev + 1;
    });
  }, 1000);

  speak('ë…¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ìµœëŒ€ 10ì´ˆì…ë‹ˆë‹¤.');
}, [speak, stopCamera, stopRecording]);


// 3ï¸âƒ£ ë…¹í™” í† ê¸€ ë²„íŠ¼ìš©
const toggleRecording = useCallback((): void => {
  if (isRecording) {
    stopRecording();
  } else {
    startRecording();
  }
}, [isRecording, startRecording, stopRecording]);



  // ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ
  const handleImageUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;
    if (!file.type.startsWith('image/')) {
      setError('ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }
    const reader = new FileReader();
    reader.onload = (e) => {
      setImage(e.target?.result as string);
      setVideo(null);
      setMediaType('image');
      setConversation([]);
      setError(null);
      speak('ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    };
    reader.readAsDataURL(file);
  }, [speak]);

  // ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
  const handleVideoUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;
    if (!file.type.startsWith('video/')) {
      setError('ë¹„ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }
    // íŒŒì¼ í¬ê¸° ì œí•œ (50MB)
    if (file.size > 50 * 1024 * 1024) {
      setError('ë¹„ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 50MB)');
      return;
    }
    const reader = new FileReader();
    reader.onload = (e) => {
      setVideo(e.target?.result as string);
      setImage(null);
      setMediaType('video');
      setConversation([]);
      setError(null);
      speak('ì˜ìƒì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      setTimeout(() => questionInputRef.current?.focus(), 100);
    };
    reader.readAsDataURL(file);
  }, [speak]);

  // ì§ˆë¬¸ ì œì¶œ
  const handleSubmit = useCallback(async (e?: React.FormEvent) => {
    e?.preventDefault();

    if (!image && !video) {
      setError('ë¨¼ì € ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
      speak('ë¨¼ì € ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
      return;
    }
    if (!question.trim()) {
      setError('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      speak('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsLoading(true);
    setError(null);
    setStreamingText('');
    speak('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤.');

    const newQuestion: ConversationItem = {
      type: 'question',
      text: question,
      timestamp: new Date(),
    };
    setConversation(prev => [...prev, newQuestion]);
    const currentQuestion = question;
    setQuestion('');

    abortControllerRef.current = new AbortController();

    try {
      const endpoint = mediaType === 'video' ? '/api/ask-video-stream' : '/api/ask-stream';
      const body = mediaType === 'video' 
        ? { video_base64: video, question: currentQuestion, language: 'ko' }
        : { image_base64: image, question: currentQuestion, language: 'ko' };

      const response = await fetch(`${API_URL}${endpoint}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
        signal: abortControllerRef.current.signal,
      });

      if (!response.ok) throw new Error('ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜');

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullText = '';

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n');
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              if (data === '[DONE]') break;
              fullText += data;
              setStreamingText(fullText);
            }
          }
        }
      }

      const newAnswer: ConversationItem = {
        type: 'answer',
        text: fullText,
        timestamp: new Date(),
      };
      setConversation(prev => [...prev, newAnswer]);
      setStreamingText('');
      speak(fullText);

    } catch (err) {
      if ((err as Error).name !== 'AbortError') {
        console.error('API error:', err);
        setError('ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        speak('ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }
    } finally {
      setIsLoading(false);
      abortControllerRef.current = null;
    }
  }, [image, video, mediaType, question, speak]);

  // ì „ì²´ ì„¤ëª…
  const handleDescribe = useCallback(async () => {
    if (!image && !video) {
      speak('ë¨¼ì € ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsLoading(true);
    setStreamingText('');
    speak(mediaType === 'video' ? 'ì˜ìƒì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.' : 'ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.');

    const describeQuestion: ConversationItem = {
      type: 'question',
      text: mediaType === 'video' ? 'ì´ ì˜ìƒì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.' : 'ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.',
      timestamp: new Date(),
    };
    setConversation(prev => [...prev, describeQuestion]);

    abortControllerRef.current = new AbortController();

    try {
      const endpoint = mediaType === 'video' ? '/api/describe-video-stream' : '/api/describe-stream';
      const body = mediaType === 'video'
        ? { video_base64: video, question: '', language: 'ko' }
        : { image_base64: image, question: '', language: 'ko' };

      const response = await fetch(`${API_URL}${endpoint}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
        signal: abortControllerRef.current.signal,
      });

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullText = '';

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n');
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              if (data === '[DONE]') break;
              fullText += data;
              setStreamingText(fullText);
            }
          }
        }
      }

      const newAnswer: ConversationItem = {
        type: 'answer',
        text: fullText,
        timestamp: new Date(),
      };
      setConversation(prev => [...prev, newAnswer]);
      setStreamingText('');
      speak(fullText);

    } catch (err) {
      if ((err as Error).name !== 'AbortError') {
        speak('ì„¤ëª…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
    } finally {
      setIsLoading(false);
      abortControllerRef.current = null;
    }
  }, [image, video, mediaType, speak]);

  // ë¦¬ì…‹
  const handleReset = useCallback(() => {
    setImage(null);
    setVideo(null);
    setMediaType('image');
    setConversation([]);
    setQuestion('');
    setError(null);
    setStreamingText('');
    stopCamera();
    stopStreaming();
    speak('ìƒˆë¡œìš´ ì´ë¯¸ì§€ë‚˜ ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.');
  }, [stopCamera, stopStreaming, speak]);

  // ì •ë¦¬
  useEffect(() => {
    return () => {
      stopCamera();
      stopSpeaking();
      stopStreaming();
    };
  }, [stopCamera, stopSpeaking, stopStreaming]);

  // í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.ctrlKey && e.key === 'Enter') handleSubmit();
      if (e.key === 'Escape') { stopSpeaking(); stopStreaming(); }
    };
    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [handleSubmit, stopSpeaking, stopStreaming]);

  return (
    <div className="app" role="application" aria-label="ì‹œê° ë„ìš°ë¯¸">
      <header className="header">
        <h1>ğŸ‘ï¸ ì‹œê° ë„ìš°ë¯¸</h1>
        <p className="subtitle">ì´ë¯¸ì§€ì™€ ì˜ìƒì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”</p>

        <div className="tts-toggle">
          <label htmlFor="tts-checkbox" className="tts-label">
            <input
              id="tts-checkbox"
              type="checkbox"
              checked={ttsEnabled}
              onChange={(e) => setTtsEnabled(e.target.checked)}
            />
            <span>ğŸ”Š ìŒì„± ì•ˆë‚´ {ttsEnabled ? 'ì¼œì§' : 'êº¼ì§'}</span>
          </label>
          {isSpeaking && (
            <button onClick={stopSpeaking} className="stop-speaking-btn">
              â¹ï¸ ìŒì„± ì¤‘ì§€
            </button>
          )}
        </div>
      </header>

      <main className="main-content">
        {/* ë¯¸ë””ì–´ ì˜ì—­ */}
        <section className="image-section" aria-label="ë¯¸ë””ì–´ ì˜ì—­">
          {!image && !video && !cameraActive && (
            <div className="image-input-area">
              <div className="media-buttons">
                <button onClick={startCamera} className="btn btn-primary btn-large">
                  ğŸ“· ì¹´ë©”ë¼
                </button>
                <button onClick={() => fileInputRef.current?.click()} className="btn btn-secondary btn-large">
                  ğŸ–¼ï¸ ì´ë¯¸ì§€
                </button>
                <button onClick={() => videoFileInputRef.current?.click()} className="btn btn-secondary btn-large">
                  ğŸ¬ ì˜ìƒ
                </button>
              </div>

              <input
                ref={fileInputRef}
                type="file"
                accept="image/*"
                onChange={handleImageUpload}
                className="hidden-input"
              />
              <input
                ref={videoFileInputRef}
                type="file"
                accept="video/*"
                onChange={handleVideoUpload}
                className="hidden-input"
              />
            </div>
          )}

         {cameraActive && (
  <div className="camera-area">
    <video
      ref={videoRef}
      autoPlay
      playsInline
      muted
      className="camera-preview"
    />

    {isRecording && (
      <div className="recording-indicator">
        ğŸ”´ ë…¹í™” ì¤‘ {recordingTime}ì´ˆ / 10ì´ˆ
      </div>
    )}

    <div className="camera-controls">
      <button
        onClick={capturePhoto}
        className="btn btn-capture"
        disabled={isRecording}
      >
        ğŸ“¸ ì‚¬ì§„
      </button>

      {/* âœ… ì—¬ê¸°: ë…¹í™” í† ê¸€ ë²„íŠ¼ */}
      <button
        type="button"
        onClick={toggleRecording}
        className={`btn ${isRecording ? 'btn-stop-record' : 'btn-record'}`}
      >
        {isRecording ? 'â¹ï¸ ë…¹í™” ì¤‘ì§€' : 'ğŸ¬ ë…¹í™” ì‹œì‘'}
      </button>

      <button onClick={stopCamera} className="btn btn-cancel">
        âŒ ì·¨ì†Œ
      </button>
    </div>
  </div>
)}


          {image && (
            <div className="image-preview-area">
              <div className="media-badge">ğŸ“· ì´ë¯¸ì§€</div>
              <img src={image} alt="ì—…ë¡œë“œëœ ì´ë¯¸ì§€" className="image-preview" />
              <div className="image-actions">
                <button onClick={handleDescribe} className="btn btn-describe" disabled={isLoading}>
                  ğŸ“ ì „ì²´ ì„¤ëª…
                </button>
                <button onClick={handleReset} className="btn btn-reset">
                  ğŸ”„ ìƒˆë¡œ ì‹œì‘
                </button>
              </div>
            </div>
          )}

          {video && (
            <div className="image-preview-area">
              <div className="media-badge">ğŸ¬ ì˜ìƒ</div>
              <video src={video} controls className="video-preview" />
              <div className="image-actions">
                <button onClick={handleDescribe} className="btn btn-describe" disabled={isLoading}>
                  ğŸ“ ì „ì²´ ì„¤ëª…
                </button>
                <button onClick={handleReset} className="btn btn-reset">
                  ğŸ”„ ìƒˆë¡œ ì‹œì‘
                </button>
              </div>
            </div>
          )}

          <canvas ref={canvasRef} className="hidden-canvas" />
        </section>

        {/* ëŒ€í™” ì˜ì—­ */}
        {(image || video) && (
          <section className="conversation-section" aria-label="ëŒ€í™” ì˜ì—­">
            <div className="conversation-list" role="log" aria-live="polite">
              {conversation.length === 0 && !streamingText && (
                <p className="empty-message">
                  {mediaType === 'video' ? 'ì˜ìƒ' : 'ì´ë¯¸ì§€'}ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.
                  <br />
                  ì˜ˆ: "ë­ê°€ ë³´ì—¬?", "ë­í•˜ê³  ìˆì–´?", "ë‚ ì”¨ê°€ ì–´ë•Œ?"
                </p>
              )}

              {conversation.map((item, index) => (
                <div key={index} className={`message ${item.type}`}>
                  <span className="message-icon">{item.type === 'question' ? 'â“' : 'ğŸ’¬'}</span>
                  <p className="message-text">{item.text}</p>
                  {item.type === 'answer' && (
                    <button onClick={() => speak(item.text)} className="btn-speak">ğŸ”Š</button>
                  )}
                </div>
              ))}

              {streamingText && (
                <div className="message answer streaming">
                  <span className="message-icon">ğŸ’¬</span>
                  <p className="message-text">
                    {streamingText}<span className="cursor">â–Œ</span>
                  </p>
                </div>
              )}

              {isLoading && !streamingText && (
                <div className="message answer loading">
                  <span className="loading-spinner">â³</span>
                  <p>ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
                </div>
              )}

              <div ref={conversationEndRef} />
            </div>

            <form onSubmit={handleSubmit} className="question-form">
              <div className="input-wrapper">
                <textarea
                  ref={questionInputRef}
                  value={question}
                  onChange={(e) => setQuestion(e.target.value)}
                  placeholder={`${mediaType === 'video' ? 'ì˜ìƒ' : 'ì´ë¯¸ì§€'}ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...`}
                  className="question-input"
                  disabled={isLoading}
                  rows={2}
                />
                <button
                  type="button"
                  onClick={toggleListening}
                  className={`btn btn-mic ${isListening ? 'listening' : ''}`}
                  disabled={isLoading}
                >
                  {isListening ? 'ğŸ”´' : 'ğŸ¤'}
                </button>
              </div>
              <div className="form-buttons">
                <button type="submit" className="btn btn-send" disabled={isLoading || !question.trim()}>
                  {isLoading ? 'â³' : 'ğŸ“¤'} ë³´ë‚´ê¸°
                </button>
                {isLoading && (
                  <button type="button" onClick={stopStreaming} className="btn btn-stop">
                    â¹ï¸ ì¤‘ì§€
                  </button>
                )}
              </div>
            </form>
          </section>
        )}

        {error && (
          <div className="error-message" role="alert">
            âš ï¸ {error}
          </div>
        )}
      </main>

      <footer className="footer">
        <p>
          ğŸ¤ ë§ˆì´í¬ë¡œ ìŒì„± ì§ˆë¬¸ | ğŸ¬ 10ì´ˆ ì˜ìƒ ë…¹í™” | Ctrl+Enter (ì „ì†¡) | ESC (ì¤‘ì§€)
        </p>
      </footer>
    </div>
  );
}

export default App;